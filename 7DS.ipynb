{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af969015-5ab1-4223-a5bc-c8742f82419f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\prash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e87fe628-cf20-456e-99b5-3ed5d8b2cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98caeb6-42c8-4368-ad25-8f0a8ab79bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\" Data science combines statistics, machine learning, and domain knowledge\n",
    "It helps businesses make informed decisions by uncovering patterns and trends. With the\n",
    "data science plays a crucial role in various industries, but challenges like data quantity\n",
    "Collaboration and ongoing research are key to maximizing its potential.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c93f2c25-3fb7-4770-a64c-4b7806705934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['Data', 'science', 'combines', 'statistics', ',', 'machine', 'learning', ',', 'and', 'domain', 'knowledge', 'It', 'helps', 'businesses', 'make', 'informed', 'decisions', 'by', 'uncovering', 'patterns', 'and', 'trends', '.', 'With', 'the', 'data', 'science', 'plays', 'a', 'crucial', 'role', 'in', 'various', 'industries', ',', 'but', 'challenges', 'like', 'data', 'quantity', 'Collaboration', 'and', 'ongoing', 'research', 'are', 'key', 'to', 'maximizing', 'its', 'potential', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(document)\n",
    "print(\"Original Words:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e7d1c0-d6a4-43e5-a167-f1e089c632fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging: [('Data', 'NNP'), ('science', 'NN'), ('combines', 'NNS'), ('statistics', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('and', 'CC'), ('domain', 'NN'), ('knowledge', 'NN'), ('It', 'PRP'), ('helps', 'VBZ'), ('businesses', 'NNS'), ('make', 'VBP'), ('informed', 'VBN'), ('decisions', 'NNS'), ('by', 'IN'), ('uncovering', 'VBG'), ('patterns', 'NNS'), ('and', 'CC'), ('trends', 'NNS'), ('.', '.'), ('With', 'IN'), ('the', 'DT'), ('data', 'NNS'), ('science', 'NN'), ('plays', 'VBZ'), ('a', 'DT'), ('crucial', 'JJ'), ('role', 'NN'), ('in', 'IN'), ('various', 'JJ'), ('industries', 'NNS'), (',', ','), ('but', 'CC'), ('challenges', 'NNS'), ('like', 'IN'), ('data', 'NNS'), ('quantity', 'NN'), ('Collaboration', 'NNP'), ('and', 'CC'), ('ongoing', 'JJ'), ('research', 'NN'), ('are', 'VBP'), ('key', 'JJ'), ('to', 'TO'), ('maximizing', 'VBG'), ('its', 'PRP$'), ('potential', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos = pos_tag(words)\n",
    "print(\"POS tagging:\", pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d7745d-2d1d-472e-8d98-c72078ce0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words removed: ['Data', 'science', 'combines', 'statistics', ',', 'machine', 'learning', ',', 'domain', 'knowledge', 'helps', 'businesses', 'make', 'informed', 'decisions', 'uncovering', 'patterns', 'trends', '.', 'data', 'science', 'plays', 'crucial', 'role', 'various', 'industries', ',', 'challenges', 'like', 'data', 'quantity', 'Collaboration', 'ongoing', 'research', 'key', 'maximizing', 'potential', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in words if word.lower() not in stop_words and word]\n",
    "print(\"Stop words removed:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f775212-f816-4672-8511-a653a3f243a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens: ['data', 'scienc', 'combin', 'statist', ',', 'machin', 'learn', ',', 'domain', 'knowledg', 'help', 'busi', 'make', 'inform', 'decis', 'uncov', 'pattern', 'trend', '.', 'data', 'scienc', 'play', 'crucial', 'role', 'variou', 'industri', ',', 'challeng', 'like', 'data', 'quantiti', 'collabor', 'ongo', 'research', 'key', 'maxim', 'potenti', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc15ab4c-8e3a-4f7e-9ad8-c1570f960833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization: ['Data', 'science', 'combine', 'statistic', ',', 'machine', 'learning', ',', 'domain', 'knowledge', 'help', 'business', 'make', 'informed', 'decision', 'uncovering', 'pattern', 'trend', '.', 'data', 'science', 'play', 'crucial', 'role', 'various', 'industry', ',', 'challenge', 'like', 'data', 'quantity', 'Collaboration', 'ongoing', 'research', 'key', 'maximizing', 'potential', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"Lemmatization:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42a2280b-700b-48d9-beba-5c653dd41b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "[[0.39056673 0.13018891 0.13018891 0.13018891 0.13018891 0.13018891\n",
      "  0.13018891 0.13018891 0.13018891 0.39056673 0.13018891 0.13018891\n",
      "  0.13018891 0.13018891 0.13018891 0.13018891 0.13018891 0.13018891\n",
      "  0.13018891 0.13018891 0.13018891 0.13018891 0.13018891 0.13018891\n",
      "  0.13018891 0.13018891 0.13018891 0.13018891 0.13018891 0.13018891\n",
      "  0.13018891 0.13018891 0.26037782 0.13018891 0.13018891 0.13018891\n",
      "  0.13018891 0.13018891 0.13018891 0.13018891]]\n",
      "Terms: ['and' 'are' 'businesses' 'but' 'by' 'challenges' 'collaboration'\n",
      " 'combines' 'crucial' 'data' 'decisions' 'domain' 'helps' 'in'\n",
      " 'industries' 'informed' 'it' 'its' 'key' 'knowledge' 'learning' 'like'\n",
      " 'machine' 'make' 'maximizing' 'ongoing' 'patterns' 'plays' 'potential'\n",
      " 'quantity' 'research' 'role' 'science' 'statistics' 'the' 'to' 'trends'\n",
      " 'uncovering' 'various' 'with']\n"
     ]
    }
   ],
   "source": [
    "documents = [document]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform (documents)\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "print(\"Terms:\", terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f33e0-4acb-4273-9bbf-97a48e08cdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fdd22-5bf3-4cf4-914c-2f2000a80a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31a7f1-4045-4ef9-bec5-cf8287d41437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
